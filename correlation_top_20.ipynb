{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62fc046-ea49-4898-9c05-89e1aecd3aae",
   "metadata": {},
   "source": [
    "# Correlation Analysis for Top 20 Stocks in the S&P 500\n",
    "\n",
    "## Acquiring Ticker Symbols for Analysis\n",
    "\n",
    "### To conduct a thorough analysis of the largest stocks by market capitalization in the S&P 500, we have two primary methods for obtaining the necessary ticker symbols:\n",
    "\n",
    "1. ***Web Scraping***: This approach involves programmatically navigating to a financial website and extracting the list of ticker symbols. This method ensures that the data is up-to-date and reflects the latest market changes.\n",
    "\n",
    "2. ***CSV Utilization***: Alternatively, we can use a precompiled CSV file containing the list of ticker symbols. While this is simpler and faster, it's important to ensure that the CSV data is current and accurate to reflect the top stocks at the time of analysis.\n",
    "Choose the method that best suits the requirements for currency and convenience for the correlation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cde3d5-c8e6-4a5a-9a26-f86cec1a3845",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'WEBSITE_URL': No scheme supplied. Perhaps you meant https://WEBSITE_URL?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWEBSITE_URL\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Paste URL\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Make a request to the website\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m webpage \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Parse the webpage with BeautifulSoup\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    483\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    485\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 486\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'WEBSITE_URL': No scheme supplied. Perhaps you meant https://WEBSITE_URL?"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the page\n",
    "url = 'WEBSITE_URL' # Paste URL\n",
    "\n",
    "# Make a request to the website\n",
    "response = requests.get(url)\n",
    "webpage = response.text\n",
    "\n",
    "# Parse the webpage with BeautifulSoup\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "# Assume the data is stored in a table with an identifiable class or id\n",
    "# This is a generic example; you'll need to inspect the webpage to find the correct tags/classes\n",
    "table = soup.find('table', class_='FILL_IN')\n",
    "  # Replace 'the_table_id' with the actual ID or class\n",
    "\n",
    "ticker_symbols = []\n",
    "\n",
    "\n",
    "\n",
    "if table:\n",
    "    # Extract and print the ticker symbols from the second column of each row\n",
    "    for row in table.find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) > 1:  # Ensure there are at least two columns\n",
    "            ticker_symbol = cells[1].text.strip()  # Second column for the symbol\n",
    "            ticker_symbols.append(ticker_symbol)\n",
    "else:\n",
    "    print(\"Table not found. Check the class name or table structure.\")\n",
    "\n",
    "df_tickers = pd.DataFrame(ticker_symbols, columns=['Ticker'])\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "print(df_tickers)\n",
    "print(today)\n",
    "\n",
    "\n",
    "csv_file_path = '/Users/LOGIN/Desktop/top_50_spy_tickers.csv'  # Define the path and filename for your CSV file\n",
    "df_tickers.to_csv(csv_file_path, index=False)  # Set index=False to avoid writing row indices to the CSV file\n",
    "\n",
    "print(f\"Data exported successfully to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ead56-1fc8-42bc-9b9c-9e78902a3a69",
   "metadata": {},
   "source": [
    "# Correlation Analysis for Select S&P 500 Stocks\n",
    "\n",
    "This Jupyter Notebook contains a Python script designed to perform a correlation analysis on the top 20 stocks from the S&P 500. The analysis follows these steps:\n",
    "\n",
    "1. **Data Acquisition**: The script starts by loading a list of ticker symbols from a CSV file located on the user's desktop. This file contains the tickers for the top 50 S&P 500 stocks by market capitalization.\n",
    "\n",
    "2. **Ticker Selection**: From the loaded list, only the first 20 tickers are selected to ensure a manageable dataset size for this demonstration.\n",
    "\n",
    "3. **Date Range Input**: The user is prompted to input the start and end dates for the data retrieval, allowing for a dynamic range of historical data to be analyzed.\n",
    "\n",
    "4. **Data Fetching**: Utilizing the `yfinance` library, historical closing prices for the selected tickers are downloaded within the user-defined date range. Any tickers without data are skipped.\n",
    "\n",
    "5. **Percentage Change Computation**: The script computes the daily percentage changes in closing prices, which is essential for understanding the volatility and the price movement over time.\n",
    "\n",
    "6. **Correlation Matrix Calculation**: A correlation matrix is calculated from these daily percentage changes, providing insight into the relationships between the stock price movements.\n",
    "\n",
    "7. **Heatmap Visualization**: A heatmap is plotted using `seaborn` to visually represent the correlation matrix, employing a green color gradient for aesthetic consistency.\n",
    "\n",
    "8. **Distribution Analysis**: To analyze the distribution of correlation coefficients, the script generates a histogram plot, offering a statistical view of how often each correlation coefficient occurs.\n",
    "\n",
    "By the end of this notebook, we'll have a clear visual and statistical understanding of how these top S&P 500 stocks correlate with one another within the specified date range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05762f85-fdb1-4804-9a13-04e7e0df55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load tickers from CSV file\n",
    "df_tickers = pd.read_csv(\"PATH/Desktop/top_50_spy_tickers.csv\")# Enter path\n",
    "\n",
    "# Assuming the ticker symbols are in a column named 'Ticker'\n",
    "tickers = df_tickers['Ticker'].tolist()\n",
    "\n",
    "# Only take the first 20 tickers for analysis\n",
    "tickers = tickers[:20]\n",
    "\n",
    "# Define the period for which you want the data\n",
    "start_date = input(\"Please enter start(yyyy-mm-dd): \")\n",
    "end_date = input(\"Please enter end(yyyy-mm-dd): \")\n",
    "\n",
    "# Create an empty DataFrame to store closing prices\n",
    "closing_prices = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and fetch the data\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    # Ensure data contains 'Close' column and has valid data (not empty)\n",
    "    if 'Close' in data and not data['Close'].empty:\n",
    "        closing_prices[ticker] = data['Close']  # Extracting the Close prices\n",
    "    else:\n",
    "        print(f\"No data for {ticker}, skipping.\")\n",
    "\n",
    "# Calculate daily percentage change\n",
    "daily_change = closing_prices.pct_change()\n",
    "\n",
    "# Calculate the correlation matrix from daily percentage changes\n",
    "correlation_matrix = daily_change.corr()\n",
    "\n",
    "# Plotting the correlation matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='BuGn', cbar=True, linewidths=0.5, ax=ax)\n",
    "plt.title('Correlation Matrix for SPY ETF Tickers')\n",
    "fig.savefig('/Users/LOGIN/Desktop/correlation_matrix.pdf')  # Save as PDF\n",
    "plt.show()\n",
    "\n",
    "# Flattening the correlation matrix and filtering out self-correlations (diagonal elements)\n",
    "flat_corr = correlation_matrix.unstack()\n",
    "flat_corr = flat_corr[flat_corr.index.get_level_values(0) != flat_corr.index.get_level_values(1)]\n",
    "\n",
    "# Plotting the distribution of correlation coefficients\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(flat_corr, bins=30, kde=True, color='green', ax=ax)\n",
    "plt.title('Distribution of Correlation Coefficients')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "fig.savefig('/Users/LOGIN/Desktop/distribution_of_correlation_coefficients.pdf')  # Save as PDF\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38697d77-a0eb-4fd2-802e-3b483b010e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
